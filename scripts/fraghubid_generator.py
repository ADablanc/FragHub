import concurrent.futures
from tqdm import tqdm
import hashlib
import ijson
import os
import re

global inchikey_update_pattern
inchikey_update_pattern = re.compile(r"([A-Z]{14}-[A-Z]{10}-[NO])", flags=re.IGNORECASE)

global peak_list_update_pattern
peak_list_update_pattern = re.compile(r"([\s\S]*:.[0-9]*\n)(((-?\d+[.,]?\d*(?:[Ee][+-]?\d+)?)(\s+|:)(-?\d+[.,]?\d*(?:[Ee][+-]?\d+)?)(.*)(\n|$))*)", flags=re.IGNORECASE)

global peak_list_split_update_pattern
peak_list_split_update_pattern = re.compile(r"(-?\d+\.?\d*(?:[Ee][+-]?\d+)?)(?:\s+|:)(-?\d+[.,]?\d*(?:[Ee][+-]?\d+)?)")

def load_spectrum_list(msp_file_path):
    """
    Load spectra from an MSP file and return a list of spectra.

    :param msp_file_path: Path to the MSP file.
    :return: List of spectra.
    """
    spectrum_list = []
    buffer = []

    total_lines = sum(1 for line in open(msp_file_path, 'r', encoding="UTF-8")) # count the total number of lines in the file

    with open(msp_file_path, 'r', encoding="UTF-8") as file:
        for line in tqdm(file, total=total_lines, unit=" rows", colour="green", desc="{:>80}".format("loading file")): # wrap this with tqdm
            if line.strip() == '':
                if buffer:
                    spectrum_list.append('\n'.join(buffer))
                    buffer = []
            else:
                if not buffer:
                    buffer.append(f"FILENAME: {os.path.basename(msp_file_path)}") # adding filename to spectrum
                buffer.append(line.strip())

    # Add the last spectrum to the list
    if buffer:
        spectrum_list.append('\n'.join(buffer))

    return spectrum_list

def hash_spectrum_data(spectrum_data):
    """
    Calculate the SHA256 hash of spectrum data.

    :param spectrum_data: The spectrum data to hash.
    :type spectrum_data: str
    :return: The SHA256 hash of spectrum data.
    :rtype: str
    """
    inchikey = re.search(inchikey_update_pattern, spectrum_data)
    peak_list = re.search(peak_list_update_pattern, spectrum_data)

    if inchikey:
        inchikey = inchikey.group(1)

    if inchikey and peak_list:
        peak_list = peak_list.group(2)
        peaks_match = re.findall(peak_list_split_update_pattern, peak_list)
        if peaks_match:
            peaks_match = [f"{i}\t{j}" for i, j in peaks_match]
            peak_list = "\n".join(peaks_match)

            spectrum_string = inchikey+"\n"+peak_list
        else:
            spectrum_string = str(spectrum_data)
    else:
        spectrum_string = str(spectrum_data)

    # Créer un objet sha256
    sha256 = hashlib.sha256()

    # Fournir les données de spectre à sha256
    sha256.update(spectrum_string.encode('utf-8'))

    # Retourner le hash sha256 en hex
    return sha256.hexdigest()

def genrate_fraghubid(spectrum):
    """
    Generate FragHubID for a given spectrum.

    :param spectrum: The spectrum data.
    :return: The spectrum data with Fragment Hub ID.
    """
    hash_key = hash_spectrum_data(spectrum)
    spectrum = f"FRAGHUBID: {str(hash_key)}\n" + spectrum

    return spectrum

def genrate_fraghubid_processing(spectrum_list, files):
    """
    Perform parallel processing of the given spectrum list and generate fraghubid for each spectrum.

    :param spectrum_list: A list of spectra.
    :return: A list of fraghubids generated for each spectrum.
    """
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = list(tqdm(executor.map(genrate_fraghubid, spectrum_list), total=len(spectrum_list), unit=" spectrums", colour="green", desc="{:>80}".format(f"generating FragHubID on [{files}]")))

    final = [res for res in results if res is not None]

    return final # returns the list of different worker executions.


def check_fraghubid_already_done(json_file_path):
    """
    Check if a FragHubID is already done in a given file.

    :param json_file_path: The file path of the JSON file to check.
    :type json_file_path: str
    :return: True if a FRAGHUBID is found, False otherwise.
    :rtype: bool
    """
    with open(json_file_path, 'r') as file:
        # ijson items returns a generator yielding items in a json file
        objects = ijson.items(file, item='item')

        first_dict = next(objects)

        # check if 'FRAGHUBID' is in the first dictionary
        if 'FRAGHUBID' in first_dict:
            return True

    # 'FRAGHUBID' was not found or file was empty
    return False

def generate_fraghub_id(json_directory_path):
    """
    :param msp_directory_path: The path to the MSP directory.
    :return: None

    This method generates a FragHub ID for each MSP file in the given directory. It loops through all the files in the directory and checks if they have a .msp extension. For each .msp file
    *, it checks if a FragHub ID has already been generated by calling the `check_fraghubid_already_done` method. If a FragHub ID hasn't been generated, it loads the spectrum list from the
    * MSP file using the `load_spectrum_list` method. Then, it processes the spectrum list to generate the FragHub ID using the `generate_fraghubid_processing` method.

    Finally, it opens the MSP file in write mode and writes the modified spectrum list with the generated FragHub ID into the file.
    """
    json_path_list = []

    for root, dirs, files in os.walk(json_directory_path):
        for file in files:
            if file.endswith(".json"):
                json_path_list.append(os.path.join(root, file))

    for files in json_path_list:
        if files.endswith(".json"):
            if not check_fraghubid_already_done(files):
                spectrum_list= load_spectrum_list(files)
                spectrum_list = genrate_fraghubid_processing(spectrum_list, files)

                with open(files, 'w', encoding='utf-8') as buffer:
                    buffer.write("\n\n\n".join(spectrum_list))