{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:59:00.103395Z",
     "start_time": "2024-11-19T09:58:56.158113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Chemin du dossier contenant les fichiers CSV\n",
    "dossier = r'D:\\Axel\\PYTHON\\FragHub\\TOOLS\\check_ontologies_completion\\data_solweig'\n",
    "\n",
    "# Lire tous les fichiers CSV dans le dossier, en excluant 'unique_inchikeys_merged.csv'\n",
    "csv_files = [f for f in os.listdir(dossier) if f.endswith('.csv') and \"unique_inchikeys_merged.csv\" not in f]\n",
    "print(csv_files)  # Vérifiez les fichiers trouvés\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Lire chaque fichier CSV et l'ajouter à la liste\n",
    "for csv_file in csv_files:\n",
    "    path = os.path.join(dossier, csv_file)\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=';')\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {csv_file}: {e}\")\n",
    "\n",
    "# Fusionner les DataFrames sur la colonne 'INCHIKEY'\n",
    "if dfs:  # Vérifier qu'il y ait au moins un dataframe\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='INCHIKEY', how='outer')\n",
    "\n",
    "    # Remplir les valeurs manquantes\n",
    "    merged_df.fillna('UNKNOWN', inplace=True)\n",
    "\n",
    "    # Supprimer les duplicata\n",
    "    merged_df.drop_duplicates(subset=['INCHIKEY'], inplace=True)\n",
    "\n",
    "    # Diviser le DataFrame en 5 parties\n",
    "    lignes_total = len(merged_df)\n",
    "    lignes_par_morceau = math.ceil(lignes_total / 5)\n",
    "\n",
    "    for partie in range(1, 6):\n",
    "        debut = (partie - 1) * lignes_par_morceau\n",
    "        fin = min(partie * lignes_par_morceau, lignes_total)\n",
    "\n",
    "        sortie_partie = f\"ontologies_dict_part_{partie}.csv\"\n",
    "        merged_df.iloc[debut:fin].to_csv(os.path.join(dossier, sortie_partie), sep=';', index=False)\n",
    "\n",
    "        print(f'{sortie_partie} sauvegardé avec {fin - debut} lignes.')\n",
    "\n",
    "    print(f\"La fusion des fichiers est terminée en 5 parties dans le dossier {dossier}.\")\n",
    "else:\n",
    "    print(\"Aucun fichier CSV trouvé ou lu correctement.\")\n"
   ],
   "id": "776d8def1fd830fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLassyFireOutput.csv', 'NPClass070723.csv']\n",
      "ontologies_dict_part_1.csv sauvegardé avec 200351 lignes.\n",
      "ontologies_dict_part_2.csv sauvegardé avec 200351 lignes.\n",
      "ontologies_dict_part_3.csv sauvegardé avec 200351 lignes.\n",
      "ontologies_dict_part_4.csv sauvegardé avec 200351 lignes.\n",
      "ontologies_dict_part_5.csv sauvegardé avec 200347 lignes.\n",
      "La fusion des fichiers est terminée en 5 parties dans le dossier D:\\Axel\\PYTHON\\FragHub\\TOOLS\\check_ontologies_completion\\data_solweig.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
